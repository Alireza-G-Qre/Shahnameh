{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf03d57",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"center\" style=\"font-family:Arab\">\n",
    "    <strong>\n",
    "        بسم الله الرحمان الرحیم\n",
    "    </strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a4736e",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"center\" style=\"font-family:Arab; font-size:26px\">\n",
    "     درس بازیابی پیشرفته اطلاعات - بهار 1400-1401\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd9a42a",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\" style=\"font-family:Arab; font-size:26\">\n",
    "    <h1>\n",
    "        <strong>\n",
    "            شاهنامه\n",
    "        </strong>\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aff26c",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\" style=\"font-family:Arab; font-size:20\">\n",
    "    <h1>\n",
    "        <strong>\n",
    "            مقدمه\n",
    "        </strong>\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbd5b4f",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\" style=\"font-family:Arab;\">\n",
    "    در این پروژه ابتدا ابیات شاهنامه را با parse کردن فایل سایت قائمیه استخراج کردیم.\n",
    "    سپس با روش‌های مختلف این ابیات را به بردارهایی تبدیل کردیم که بتوان با استفاده از cosine similarity،\n",
    "    ابیات مشابه با یک جمله یا بیت ورودی را در شاهنامه پیدا کرد. برای این کار از ۴ روش استفاده کردیم\n",
    "    که دو روش اول مبتنی بر خود ابیات بوده و در دو روش دوم از embedding هایی که از قبل train شده‌اند استفاده کردیم.\n",
    "    </br> \n",
    "    همچنین با آزمون و خطا متوجه شدیم حذف ایست‌واژه‌ها در دو روش اول مفید است چون باعث می‌شود شباهت فقط بین کلمات مهم بررسی شده و کلمات کم اهمیت‌تر در نظر گرفته نشوند،\n",
    "    ولی در دو روش دوم حذف نکردن آن‌ها مفیدتر است چون اگر این ایست‌واژه‌ها بی‌اهمیت باشند در embedding نیز تاثیر کمی خواهند داشت و اگر مهم باشند، با حذفشان دقت را کاهش نداده‌ایم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf56b3",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\" style=\"font-family:Arab; font-size:20\">\n",
    "    <h1>\n",
    "        <strong>\n",
    "            آماده‌سازی\n",
    "        </strong>\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f75404",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\" style=\"font-family:Arab;\">\n",
    "    در این قسمت ابتدا کتابخانه‌های مورد نیاز نصب شده‌اند و سپس با اجرای فایل\n",
    "    html_extractor،\n",
    "    ابیات استخراج می‌شوند.\n",
    "    البته با توجه به تفاوت نصب pytorch در سیستم عامل‌های مختلف، لازم است به طور جداگانه نصب شود.\n",
    "    </br>\n",
    "    در این قسمت تابع clean_poems وظیفه‌ی حذف ایست‌واژه‌ها و نرمال‌سازی را داشته که در دو قسمت اول استفاده می‌شود\n",
    "    و تابع get_similars_by_cosine_distance با دریافت ورودی، ابیات مشابه آن را بر می‌گرداند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c5f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas numpy hazm scikit-learn gensim transformers scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069b3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python ./html_extractor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a37c9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "poems = list(line.strip() for line in\n",
    "             io.open('../datasets/shahnameh.txt', mode=\"r\", encoding=\"utf-8\").readlines())\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hazm\n",
    "\n",
    "# TODO: better stopwords to improve\n",
    "costums = [\n",
    "    'زین',\n",
    "    'مگر',\n",
    "    'اندر',\n",
    "    'چو',\n",
    "    'گر',\n",
    "    'کز',\n",
    "    'پس',\n",
    "]\n",
    "stopwords = set(hazm.stopwords_list() + costums)\n",
    "\n",
    "poems = np.array(poems)\n",
    "poems = np.apply_along_axis(' / '.join, 1, poems.reshape(-1, 2))\n",
    "\n",
    "df = pd.DataFrame(poems, columns=['poems'])\n",
    "\n",
    "normalizer = hazm.Normalizer(token_based=True)\n",
    "\n",
    "# find better persian poems normalization and cleaning\n",
    "def clean_poems(poem):\n",
    "    tokens = [tk for tk in hazm.word_tokenize(poem) if tk not in stopwords and len(tk) > 1]\n",
    "    text = ' '.join(tokens)\n",
    "    return normalizer.normalize(text)\n",
    "\n",
    "eps = 1e-10\n",
    "\n",
    "def get_similars_by_cosine_distance(vector, documents, n=5):\n",
    "    sq_vector = np.squeeze(vector)\n",
    "    similarity = documents.dot(sq_vector) / (np.linalg.norm(documents, axis=1) * np.linalg.norm(sq_vector) + eps)\n",
    "    sorted_indx = np.argsort(similarity)\n",
    "    \n",
    "    return list(zip(df.poems[sorted_indx[-n:]], similarity[sorted_indx[-n:]]))\n",
    "\n",
    "df['changed'] = df.poems.apply(clean_poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a39727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poems</th>\n",
       "      <th>changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13539</th>\n",
       "      <td>میان دو بیشه بیک روزه راه / فرود آمد آن گرد لش...</td>\n",
       "      <td>بیشه بیک روزه فرود گرد لشکر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35678</th>\n",
       "      <td>بران سفت سیمنش مشکین کمند / سرش گشته چون حلقهٔ...</td>\n",
       "      <td>بران سفت سیمنش مشکین کمند سرش گشته حلقهٔ پای</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>بگویی به پیران که من با سپاه / بزیبد رسیدم بفر...</td>\n",
       "      <td>بگویی پیران سپاه بزیبد رسیدم بفرمان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31667</th>\n",
       "      <td>چنین گفت کین شیده خال منست / ببالا و مردی همال...</td>\n",
       "      <td>کین شیده خال منست ببالا مردی همال منس</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16725</th>\n",
       "      <td>کتایون چو بشنید شد پر ز خشم / به پیش پسر شد پر...</td>\n",
       "      <td>کتایون بشنید خشم پسر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34560</th>\n",
       "      <td>خرد یافته موبد نیک بخت / به فرزند زد داستان درخت</td>\n",
       "      <td>خرد موبد نیک‌بخت فرزند زد داستان درخت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10599</th>\n",
       "      <td>ازان شهرها هرک درویش بود / وگر نانش از کوشش خو...</td>\n",
       "      <td>ازان شهرها هرک درویش وگر نانش کوشش</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18569</th>\n",
       "      <td>بمابر کنون تلخ گردد جهان / خروشان شویم آشکار و...</td>\n",
       "      <td>بمابر کنون تلخ جهان خروشان شویم آشکار نها</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36449</th>\n",
       "      <td>همو تاج و تخت بلندی دهد / همو تیرگی و نژندی دهد</td>\n",
       "      <td>همو تاج تخت بلندی همو تیرگی نژندی</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20566</th>\n",
       "      <td>همی تاخت چون گرد با اسپنوی / سوی راه توران نها...</td>\n",
       "      <td>همی تاخت گرد اسپنوی توران نهادند</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   poems  \\\n",
       "13539  میان دو بیشه بیک روزه راه / فرود آمد آن گرد لش...   \n",
       "35678  بران سفت سیمنش مشکین کمند / سرش گشته چون حلقهٔ...   \n",
       "379    بگویی به پیران که من با سپاه / بزیبد رسیدم بفر...   \n",
       "31667  چنین گفت کین شیده خال منست / ببالا و مردی همال...   \n",
       "16725  کتایون چو بشنید شد پر ز خشم / به پیش پسر شد پر...   \n",
       "34560   خرد یافته موبد نیک بخت / به فرزند زد داستان درخت   \n",
       "10599  ازان شهرها هرک درویش بود / وگر نانش از کوشش خو...   \n",
       "18569  بمابر کنون تلخ گردد جهان / خروشان شویم آشکار و...   \n",
       "36449    همو تاج و تخت بلندی دهد / همو تیرگی و نژندی دهد   \n",
       "20566  همی تاخت چون گرد با اسپنوی / سوی راه توران نها...   \n",
       "\n",
       "                                            changed  \n",
       "13539                   بیشه بیک روزه فرود گرد لشکر  \n",
       "35678  بران سفت سیمنش مشکین کمند سرش گشته حلقهٔ پای  \n",
       "379             بگویی پیران سپاه بزیبد رسیدم بفرمان  \n",
       "31667         کین شیده خال منست ببالا مردی همال منس  \n",
       "16725                          کتایون بشنید خشم پسر  \n",
       "34560         خرد موبد نیک‌بخت فرزند زد داستان درخت  \n",
       "10599            ازان شهرها هرک درویش وگر نانش کوشش  \n",
       "18569     بمابر کنون تلخ جهان خروشان شویم آشکار نها  \n",
       "36449             همو تاج تخت بلندی همو تیرگی نژندی  \n",
       "20566              همی تاخت گرد اسپنوی توران نهادند  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbfb892",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\" style=\"font-family:Arab; font-size:20\">\n",
    "    <h1>\n",
    "        <strong>\n",
    "            استفاده از tf-idf و boolean\n",
    "        </strong>\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ad1a15",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\" style=\"font-family:Arab;\">\n",
    "    در این قسمت با توجه به شباهت این دو روش، خروجی آن‌ها در کنار هم بررسی و چاپ شده‌است.\n",
    "    همانطور که مشخص است شباهت با بیت داده شده ۱ بوده و ابیات مشابه دیگر نیز با توجه به منطق مورد استفاده، با دقت‌های مشخص، پیدا شده‌اند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3933aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('count', CountVectorizer(analyzer='word', ngram_range=(1, 1), max_features=20_000)),\n",
    "                 ('tfidf', TfidfTransformer(sublinear_tf=True))]).fit(df.changed)\n",
    "\n",
    "def get_document_vectors(series):\n",
    "    series = [clean_poems(doc) for doc in series]\n",
    "    boolw_vec = pipe['count'].transform(series).toarray().astype(bool).astype(int)\n",
    "    norm = np.linalg.norm(boolw_vec, axis=1).reshape(-1, 1)\n",
    "    return pipe.transform(series).toarray() , boolw_vec / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f110f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_documents, boolw_documents = get_document_vectors(df.poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "796eb235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "tfidf: دلیران و گردان توران سپاه / بسی نیز با او فگنده به \t with similarity of 0.36\n",
      "tfidf: شود / به نزدیک شاه دلیران شود                      \t with similarity of 0.39\n",
      "tfidf: که شایستهٔ جنگ شیران منم / هم آورد سالار ایران منم \t with similarity of 0.40\n",
      "tfidf: ز توران به خرم به ایران برم / وگر سوی دشت دلیران ب \t with similarity of 0.42\n",
      "tfidf: که خوکردهٔ جنگ توران منم / یکی نامداری از ایران من \t with similarity of 0.42\n",
      "tfidf: هم آورد این نره شیران منم / خریدار جنگ دلیران منم  \t with similarity of 0.44\n",
      "tfidf: نگهدار ایران نیران توی / به هر جای پشت دلیران توی  \t with similarity of 0.45\n",
      "tfidf: بدو گفت اگر شاه ایران تویی / نگهدار پشت دلیران توی \t with similarity of 0.52\n",
      "tfidf: شهنشاه ایران و توران منم / سپهدار و پشت دلیران منم \t with similarity of 0.70\n",
      "tfidf: نگهدار ایران و توران منم / به هر جای پشت دلیران من \t with similarity of 1.00\n",
      "----------------------------------------------------------------------------------------------------\n",
      "boolw: که خسرو ز توران به ایران رسید / نشست از بر تخت کو  \t with similarity of 0.40\n",
      "boolw: چو پیروز شد سوی ایران کشید / بر شهریار دلیران کشید \t with similarity of 0.40\n",
      "boolw: نباید که این خانه ویران شود / به کام دلیران ایران  \t with similarity of 0.40\n",
      "boolw: چو نزدیکی شهر ایران رسید / به جای دلیران و شیران ر \t with similarity of 0.40\n",
      "boolw: بدو گفت اگر شاه ایران تویی / نگهدار پشت دلیران توی \t with similarity of 0.51\n",
      "boolw: ز توران به خرم به ایران برم / وگر سوی دشت دلیران ب \t with similarity of 0.51\n",
      "boolw: که خوکردهٔ جنگ توران منم / یکی نامداری از ایران من \t with similarity of 0.55\n",
      "boolw: نگهدار ایران نیران توی / به هر جای پشت دلیران توی  \t with similarity of 0.60\n",
      "boolw: شهنشاه ایران و توران منم / سپهدار و پشت دلیران منم \t with similarity of 0.73\n",
      "boolw: نگهدار ایران و توران منم / به هر جای پشت دلیران من \t with similarity of 1.00\n"
     ]
    }
   ],
   "source": [
    "tfidf_vector, boolw_vector = \\\n",
    "    get_document_vectors(['نگهدار ایران و توران منم / به هر جای پشت دلیران من'])\n",
    "\n",
    "print('-' * 100)\n",
    "for poem, sym in get_similars_by_cosine_distance(tfidf_vector, tfidf_documents, 10):\n",
    "    print(\"tfidf: {:50s} \\t with similarity of {:.2f}\".format(poem, sym))\n",
    "\n",
    "print('-' * 100)\n",
    "for poem, sym in get_similars_by_cosine_distance(boolw_vector, boolw_documents, 10):\n",
    "    print(\"boolw: {:50s} \\t with similarity of {:.2f}\".format(poem, sym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45bb31d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_idfs = dict(zip(pipe['count'].get_feature_names_out(), pipe['tfidf'].idf_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fabf22",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\" style=\"font-family:Arab; font-size:20\">\n",
    "    <h1>\n",
    "        <strong>\n",
    "            ترکیب embedding و idf\n",
    "        </strong>\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1857c61d",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\" style=\"font-family:Arab;\">\n",
    "    در این قسمت، از embedding هایی که در مدل کتابخانه‌ی gensim وجود دارد استفاده کردیم و برای نرمال‌سازی از idf که در قسمت قبل محاسبه شده‌بود، استفاده کردیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff78ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from hazm import word_tokenize\n",
    "\n",
    "word2vec = KeyedVectors.load_word2vec_format('../models/farsi_literature_word2vec_model.txt')\n",
    "\n",
    "def embed(poem):\n",
    "    def get_wrod2vector(word):\n",
    "        return word2vec[word] if word in word2vec else np.zeros(100)\n",
    "    \n",
    "    embedding_vectors = [get_wrod2vector(wo) * word_idfs.get(wo, 0) for wo in word_tokenize(poem)]\n",
    "    return np.sum(embedding_vectors, axis=0).tolist()\n",
    "\n",
    "poems_embeddings = np.array(df.poems.apply(embed).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d163d2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "embedding: به ویژه نژاد شما را که رنج / فزونست نزدیک شاهان ز  \t with similarity of 0.70\n",
      "embedding: نباید که شد جان ما بی سپاس / به نزدیک یزدان نیکی ش \t with similarity of 0.70\n",
      "embedding: همان زیردستی که فرمان شاه / به رنج و به کوشش ندارد \t with similarity of 0.70\n",
      "embedding: نیابد بدو نیز اندیشه راه / که او برتر از نام و از  \t with similarity of 0.71\n",
      "embedding: بدو گفت خاقان به برتر خدای / که هست او مرا و تو را \t with similarity of 0.72\n",
      "embedding: به نام شهنشاه شمشیرزن / به بالا سرش برتر از انجمن  \t with similarity of 0.73\n",
      "embedding: شاه زمین / که ای برتر از دانش به آفرین             \t with similarity of 0.74\n",
      "embedding: اگر زانک مهتر برادر تویی / به هوش وخرد نیز برتر تو \t with similarity of 0.74\n",
      "embedding: به یاران چنین گفت کاینت شگفت / کزین برتر اندیشه نت \t with similarity of 0.75\n",
      "embedding: به نام خداوند جان و خرد / کزین برتر اندیشه برنگذرد \t with similarity of 1.00\n"
     ]
    }
   ],
   "source": [
    "sample_embedding = np.array(embed('به نام خداوند جان و خرد / کزین برتر اندیشه برنگذرد'))\n",
    "\n",
    "print('-' * 100)\n",
    "for poem, sym in get_similars_by_cosine_distance(sample_embedding, poems_embeddings, 10):\n",
    "    print(\"embedding: {:50s} \\t with similarity of {:.2f}\".format(poem, sym))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cda6f5",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\" style=\"font-family:Arab; font-size:20\">\n",
    "    <h1>\n",
    "        <strong>\n",
    "            استفاده از مدل‌های BigBird و ParsBert\n",
    "        </strong>\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4943d424",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\" style=\"font-family:Arab;\">\n",
    "    در این قسمت به دلیل زمان زیادی که استفاده از ترنسفورمر روی کل ابیات نیاز دارد، embedding ها استخراج شده و در فایل قرار گرفته‌اند.\n",
    "    بنابراین کافی‌است ورودی به ترنسفورمر داده شود و embedding آن با embedding هایی که از فایل لود شده‌اند مقایسه شود تا ابیات مشابه پیدا شوند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93f156d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_embedding import TransformerEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11ad2e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SajjadAyoubi/distil-bigbird-fa-zwnj were not used when initializing BigBirdModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BigBirdModel were not initialized from the model checkpoint at SajjadAyoubi/distil-bigbird-fa-zwnj and are newly initialized: ['bert.pooler.weight', 'bert.pooler.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at HooshvareLab/bert-base-parsbert-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "50it [09:42, 11.64s/it]\n",
      "50it [13:51, 16.64s/it]\n"
     ]
    }
   ],
   "source": [
    "embedder = TransformerEmbedding(df, batch_size=1000)\n",
    "\n",
    "# Run only for the first time\n",
    "# embedder.run_and_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2cd13db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 20.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "embedding: که از یکدگر روی برگاشتند / دل و جان به اندوه بگذاش \t with similarity of 0.84\n",
      "embedding: ز نیکی دهش آفرین بر تو باد / فلک را گذر بر نگین تو \t with similarity of 0.84\n",
      "embedding: نه من اورمزدم و گر بهمنم / ز خاکست وز باد و آتش تن \t with similarity of 0.84\n",
      "embedding: غمی شد ز مرگ آن سر تاجور / بمرد و به شاهی نبودش پس \t with similarity of 0.84\n",
      "embedding: سخنها که گفتی تو برگست و باد / دل و جان آن بدکنش پ \t with similarity of 0.84\n",
      "embedding: چو بگرفت جای خرد آرزوی / دگر شد به رای و به آیین و \t with similarity of 0.85\n",
      "embedding: به یک جای هرگز نیامیختند / ز پند و خرد هر دو بگریخ \t with similarity of 0.85\n",
      "embedding: ترا با هنر گوهرست و خرد / روانت همی از تو رامش برد \t with similarity of 0.85\n",
      "embedding: ز هستی نشانست بر آب و خاک / ز دانش منش را مکن در م \t with similarity of 0.85\n",
      "embedding: به نام خداوند جان و خرد / کزین برتر اندیشه برنگذرد \t with similarity of 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "poems_embeddings = embedder.load_embeddings('../models/embeddings-bigbird.npz')\n",
    "\n",
    "sample_embedding = embedder.get_transformer_embedding(\n",
    "    ['به نام خداوند جان و خرد کزین برتر اندیشه برنگذرد'], 'bigbird')\n",
    "\n",
    "# TODO: better format to report similarity\n",
    "print('-' * 100)\n",
    "for poem, sym in get_similars_by_cosine_distance(sample_embedding, poems_embeddings, 10):\n",
    "    print(\"embedding: {:50s} \\t with similarity of {:.2f}\".format(poem, sym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3000d250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "embedding: کند آفرین بر خداوند مهر / کزین گونه بر پای دارد سپ \t with similarity of 0.83\n",
      "embedding: همه نام جویید و نیکی کنید / دل نیک پی مردمان مشکنی \t with similarity of 0.83\n",
      "embedding: خداوند دانایی وتاج وتخت / ز پیروزگر یافته کام و بخ \t with similarity of 0.83\n",
      "embedding: به اندیشه دل را به جای آورید / خرد را بران رهنمای  \t with similarity of 0.83\n",
      "embedding: بر آیین آن دین مر او رابخواست / بپذرفت با جان همی  \t with similarity of 0.84\n",
      "embedding: که جنبندگانند و چندی زیند / ندانند کاندر جهان برچی \t with similarity of 0.84\n",
      "embedding: ز اندرز من سربسر مگذرید / چو خواهید کز جان و تن بر \t with similarity of 0.84\n",
      "embedding: اگرهرگز این آرزو خواستم / ز یزدان وبردل بیاراستم   \t with similarity of 0.84\n",
      "embedding: کسی زین نشان هیچ برنگذرد / کزان رود برتر زمین نشمر \t with similarity of 0.84\n",
      "embedding: به نام خداوند جان و خرد / کزین برتر اندیشه برنگذرد \t with similarity of 0.97\n"
     ]
    }
   ],
   "source": [
    "poems_embeddings = embedder.load_embeddings('../models/embeddings-parsbert.npz')\n",
    "\n",
    "sample_embedding = embedder.get_transformer_embedding(\n",
    "    ['به نام خداوند جان و خرد کزین برتر اندیشه برنگذرد'], 'parsbert')\n",
    "\n",
    "# TODO: better format to report similarity\n",
    "print('-' * 100)\n",
    "for poem, sym in get_similars_by_cosine_distance(sample_embedding, poems_embeddings, 10):\n",
    "    print(\"embedding: {:50s} \\t with similarity of {:.2f}\".format(poem, sym))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3965c385",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\" style=\"font-family:Arab; font-size:20\">\n",
    "    <h1>\n",
    "        <strong>\n",
    "            نتیجه گیری\n",
    "        </strong>\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5d9ec2",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\" style=\"font-family:Arab;\">\n",
    "    با مقایسه‌ی ابیات مشابهی که هر روش پیدا کرده‌است می‌توان نتیجه گرفت روش‌هایی که مبتنی بر embedding کلمات هستند دقت بالاتری دارند چون\n",
    "    در این روش‌ها تمرکز بر معنا و اهمیت کلمات در جمله بوده و فقط به تکرار چند کلمه‌ی خاص توجه نمی‌کنیم.\n",
    "    البته بین همین روش‌ها نیز اگر ترنسفورمرها با document های ما یادگیری را انجام داده باشند یا fine tune شده باشند، می‌توانند دقت بالاتری داشته باشند چون درک دقیق‌تر و کامل‌تری از معنا و مفهوم ابیات و ورودی ما خواهند داشت.\n",
    "    البته چون هدف این پروژه train کردن مدل‌های ترنسفورمر نبوده و منابع پرداشی ما نیز محدود بودند، از همان مدل‌هایی که از قبل train شده بودند استفاده کردیم که ممکن است دقتشان کمی کمتر از انتظار باشد.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
