{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas numpy hazm scikit-learn gensim transformers scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "poems = list(line.strip() for line in\n",
    "             io.open('../datasets/shahnameh.txt', mode=\"r\", encoding=\"utf-8\").readlines())[:10_000]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hazm\n",
    "\n",
    "# TODO: better stopwords to improve\n",
    "costums = [\n",
    "    'زین',\n",
    "    'مگر',\n",
    "    'اندر',\n",
    "    'چو',\n",
    "    'گر',\n",
    "    'کز',\n",
    "    'پس',\n",
    "]\n",
    "stopwords = set(hazm.stopwords_list() + costums)\n",
    "\n",
    "poems = np.array(poems)\n",
    "poems = np.apply_along_axis(' / '.join, 1, poems.reshape(-1, 2))\n",
    "\n",
    "df = pd.DataFrame(poems, columns=['poems'])\n",
    "\n",
    "normalizer = hazm.Normalizer(token_based=True)\n",
    "\n",
    "# find better persian poems normalization and cleaning\n",
    "def clean_poems(poem):\n",
    "    tokens = [tk for tk in hazm.word_tokenize(poem) if tk not in stopwords and len(tk) > 1]\n",
    "    text = ' '.join(tokens)\n",
    "    return normalizer.normalize(text)\n",
    "\n",
    "eps = 1e-10\n",
    "\n",
    "def get_similars_by_cosine_distance(vector, documents, n=5):\n",
    "    sq_vector = np.squeeze(vector)\n",
    "    similarity = documents.dot(sq_vector) / (np.linalg.norm(documents, axis=1) * np.linalg.norm(sq_vector) + eps)\n",
    "    sorted_indx = np.argsort(similarity)\n",
    "    \n",
    "    return list(zip(df.poems[sorted_indx[-n:]], similarity[sorted_indx[-n:]]))\n",
    "\n",
    "df['changed'] = df.poems.apply(clean_poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poems</th>\n",
       "      <th>changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>که او را همی آشتی رای نیست / بدلش اندرون داد ر...</td>\n",
       "      <td>همی آشتی رای بدلش اندرون</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>درشتی نمایم چو باشم درست / انوشه کسی کو درشتی ...</td>\n",
       "      <td>درشتی نمایم چو باشم درست انوشه کو درشتی نجست</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>ببستندشان دست و پای و میان / کشیدند بر پشت زین...</td>\n",
       "      <td>ببستندشان دست پای کشیدند کیا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>که ما را ز جیحون بباید گذشت / زدن کوس شاهی برا...</td>\n",
       "      <td>جیحون بباید گذشت زدن کوس شاهی بران په</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>ببیژن نمود آنگهی هر دو تور / که بودند کشته فگن...</td>\n",
       "      <td>ببیژن نمود آنگهی تور کشته فگنده</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>چنانچون سپردی سپردم بهم / درین بود گودرز با گستهم</td>\n",
       "      <td>چنانچون سپردی سپردم بهم درین گودرز گستهم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>جهان بی سر و تاج خسرو مباد / همیشه بماناد جاوی...</td>\n",
       "      <td>جهان سر تاج خسرو مباد بماناد جاوید</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>ازین مایه ور جا بدین فرهی / دل ما ز رامش نبودی...</td>\n",
       "      <td>ازین مایه ور بدین فرهی دل رامش نبودی تهی</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>وزان لشکر ترک هومان دلیر / بپیش برادر بیامد چو...</td>\n",
       "      <td>وزان لشکر ترک هومان دلیر بپیش برادر بیامد چو شیر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>بگویم به تأیید محمود شاه / بدان فر و آن خسروان...</td>\n",
       "      <td>بگویم تأیید محمود شاه بدان فر خسروانی</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  poems  \\\n",
       "478   که او را همی آشتی رای نیست / بدلش اندرون داد ر...   \n",
       "3994  درشتی نمایم چو باشم درست / انوشه کسی کو درشتی ...   \n",
       "2588  ببستندشان دست و پای و میان / کشیدند بر پشت زین...   \n",
       "259   که ما را ز جیحون بباید گذشت / زدن کوس شاهی برا...   \n",
       "2572  ببیژن نمود آنگهی هر دو تور / که بودند کشته فگن...   \n",
       "2299  چنانچون سپردی سپردم بهم / درین بود گودرز با گستهم   \n",
       "222   جهان بی سر و تاج خسرو مباد / همیشه بماناد جاوی...   \n",
       "4086  ازین مایه ور جا بدین فرهی / دل ما ز رامش نبودی...   \n",
       "626   وزان لشکر ترک هومان دلیر / بپیش برادر بیامد چو...   \n",
       "2745  بگویم به تأیید محمود شاه / بدان فر و آن خسروان...   \n",
       "\n",
       "                                               changed  \n",
       "478                           همی آشتی رای بدلش اندرون  \n",
       "3994      درشتی نمایم چو باشم درست انوشه کو درشتی نجست  \n",
       "2588                      ببستندشان دست پای کشیدند کیا  \n",
       "259              جیحون بباید گذشت زدن کوس شاهی بران په  \n",
       "2572                   ببیژن نمود آنگهی تور کشته فگنده  \n",
       "2299          چنانچون سپردی سپردم بهم درین گودرز گستهم  \n",
       "222                 جهان سر تاج خسرو مباد بماناد جاوید  \n",
       "4086          ازین مایه ور بدین فرهی دل رامش نبودی تهی  \n",
       "626   وزان لشکر ترک هومان دلیر بپیش برادر بیامد چو شیر  \n",
       "2745             بگویم تأیید محمود شاه بدان فر خسروانی  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf and Boolean approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('count', CountVectorizer(analyzer='word', ngram_range=(1, 1), max_features=20_000)),\n",
    "                 ('tfidf', TfidfTransformer(sublinear_tf=True))]).fit(df.changed)\n",
    "\n",
    "def get_document_vectors(series):\n",
    "    series = [clean_poems(doc) for doc in series]\n",
    "    boolw_vec = pipe['count'].transform(series).toarray().astype(bool).astype(int)\n",
    "    norm = np.linalg.norm(boolw_vec, axis=1).reshape(-1, 1)\n",
    "    return pipe.transform(series).toarray() , boolw_vec / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_documents, boolw_documents = get_document_vectors(df.poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "tfidf: \"چهارم سپاه اندر آمد چو کوه / دلیران ایران گروها گر\" \t with similarity of 0.26\n",
      "tfidf: \"سیاوش رد را برادر توی / بگوهر ز سالار برتر توی\" \t with similarity of 0.26\n",
      "tfidf: \"چپ لشکر و چنگ شیران توی / نگهبان سالار ایران توی\" \t with similarity of 0.35\n",
      "tfidf: \"چو کار آیدم شهریارم تویی / همان از پدر یادگارم توی\" \t with similarity of 0.35\n",
      "tfidf: \"بدو گفت اگر شاه ایران تویی / نگهدار پشت دلیران توی\" \t with similarity of 1.00\n",
      "----------------------------------------------------------------------------------------------------\n",
      "boolw: \"چو نزدیکی شهر ایران رسید / به جای دلیران و شیران ر\" \t with similarity of 0.31\n",
      "boolw: \"چو چوپان بر شاه توران رسید / بدو باز گفت آن شگفتی \" \t with similarity of 0.31\n",
      "boolw: \"نباید که آن بوم ویران بود / که در سایهٔ شاه ایران \" \t with similarity of 0.34\n",
      "boolw: \"همه گورشان کام شیران کنم / به کام دلیران ایران کنم\" \t with similarity of 0.34\n",
      "boolw: \"بدو گفت اگر شاه ایران تویی / نگهدار پشت دلیران توی\" \t with similarity of 1.00\n"
     ]
    }
   ],
   "source": [
    "tfidf_vector, boolw_vector = \\\n",
    "    get_document_vectors(['بدو گفت اگر شاه ایران تویی / نگهدار پشت دلیران توی'])\n",
    "\n",
    "# TODO: better format to report similarity\n",
    "print('-' * 100)\n",
    "for poem, sym in get_similars_by_cosine_distance(tfidf_vector, tfidf_documents):\n",
    "    print(\"tfidf: \\\"{}\\\" \\t with similarity of {:.2f}\".format(poem, sym))\n",
    "\n",
    "print('-' * 100)\n",
    "for poem, sym in get_similars_by_cosine_distance(boolw_vector, boolw_documents):\n",
    "    print(\"boolw: \\\"{}\\\" \\t with similarity of {:.2f}\".format(poem, sym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_idfs = dict(zip(pipe['count'].get_feature_names_out(), pipe['tfidf'].idf_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining word embedding and idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from hazm import word_tokenize\n",
    "\n",
    "word2vec = KeyedVectors.load_word2vec_format('../models/farsi_literature_word2vec_model.txt')\n",
    "\n",
    "# TODO: check appropriate stopwords\n",
    "def embed(poem):\n",
    "    \n",
    "    poem = clean_poems(poem)\n",
    "    def get_wrod2vector(word):\n",
    "        return word2vec[word] if word in word2vec else np.zeros(100)\n",
    "    \n",
    "    embedding_vectors = [get_wrod2vector(wo) * word_idfs.get(wo, 0) for wo in word_tokenize(poem)]\n",
    "    return np.sum(embedding_vectors, axis=0).tolist()\n",
    "\n",
    "poems_embeddings = np.array(df.changed.apply(embed).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "embedding: \"ز بیشی خرد را بود سودمند / همان بی خرد باشد اندر گ\" \t with similarity of 0.63\n",
      "embedding: \"کزو رنج بر مهر بگزیده ای / ستایش بدین گونه بشنیده \" \t with similarity of 0.63\n",
      "embedding: \"خداوند جان و خداوند رای / خداوند نیکی ده و رهنمای\" \t with similarity of 0.66\n",
      "embedding: \"نیابد بدو نیز اندیشه راه / که او برتر از نام و از \" \t with similarity of 0.70\n",
      "embedding: \"به نام خداوند جان و خرد / کزین برتر اندیشه برنگذرد\" \t with similarity of 1.00\n"
     ]
    }
   ],
   "source": [
    "sample_embedding = np.array(embed('به نام خداوند جان و خرد / کزین برتر اندیشه برنگذرد'))\n",
    "\n",
    "# TODO: better format to report similarity\n",
    "print('-' * 100)\n",
    "for poem, sym in get_similars_by_cosine_distance(sample_embedding, poems_embeddings):\n",
    "    print(\"embedding: \\\"{}\\\" \\t with similarity of {:.2f}\".format(poem, sym))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use BigBird and ParsBert last hidden state as embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-05 23:54:33.196090: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/alireza/.mujoco/mujoco210/bin\n",
      "2022-06-05 23:54:33.196112: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from transformer_embedding import TransformerEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SajjadAyoubi/distil-bigbird-fa-zwnj were not used when initializing BigBirdModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BigBirdModel were not initialized from the model checkpoint at SajjadAyoubi/distil-bigbird-fa-zwnj and are newly initialized: ['bert.pooler.bias', 'bert.pooler.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at HooshvareLab/bert-base-parsbert-uncased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "50it [00:49,  1.00it/s]\n",
      "50it [01:24,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "embedder = TransformerEmbedding(df, batch_size=100)\n",
    "embedder.run_and_dump() # Run only for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 47.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "embedding: \"که نپسندد از ما بدی دادگر / سپنجست گیتی و ما برگذر\" \t with similarity of 0.83\n",
      "embedding: \"جهان بستد از مردم بت پرست / ز دیبای دین بر دل آیین\" \t with similarity of 0.83\n",
      "embedding: \"چو ایرانیان را دل آمد به جای / ببودند بر پیش یزدان\" \t with similarity of 0.83\n",
      "embedding: \"به راه خداوند خورشید و ماه / ز بن دور کن دیو را دس\" \t with similarity of 0.83\n",
      "embedding: \"به نام خداوند جان و خرد / کزین برتر اندیشه برنگذرد\" \t with similarity of 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "poems_embeddings = embedder.load_embeddings('../models/embeddings-bigbird.npz')\n",
    "\n",
    "sample_embedding = embedder.get_transformer_embedding(\n",
    "    ['به نام خداوند جان و خرد کزین برتر اندیشه برنگذرد'], 'bigbird')\n",
    "\n",
    "# TODO: better format to report similarity\n",
    "print('-' * 100)\n",
    "for poem, sym in get_similars_by_cosine_distance(sample_embedding, poems_embeddings):\n",
    "    print(\"embedding: \\\"{}\\\" \\t with similarity of {:.2f}\".format(poem, sym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 24.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "embedding: \"شما را جهان بازجستن بداد / نگه داشتن ارج مرد نژاد\" \t with similarity of 0.82\n",
      "embedding: \"بجستند بهره ز کشت و درود / نرستست کس پیش ازین نابس\" \t with similarity of 0.82\n",
      "embedding: \"سلیح و تن از خون ایشان بشست / بران خارستان پاک جای\" \t with similarity of 0.82\n",
      "embedding: \"که کس را ز ترکان نباشد خرد / کز اندیشهٔ خویش رامش \" \t with similarity of 0.83\n",
      "embedding: \"به نام خداوند جان و خرد / کزین برتر اندیشه برنگذرد\" \t with similarity of 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "poems_embeddings = embedder.load_embeddings('../models/embeddings-parsbert.npz')\n",
    "\n",
    "sample_embedding = embedder.get_transformer_embedding(\n",
    "    ['به نام خداوند جان و خرد کزین برتر اندیشه برنگذرد'], 'parsbert')\n",
    "\n",
    "# TODO: better format to report similarity\n",
    "print('-' * 100)\n",
    "for poem, sym in get_similars_by_cosine_distance(sample_embedding, poems_embeddings):\n",
    "    print(\"embedding: \\\"{}\\\" \\t with similarity of {:.2f}\".format(poem, sym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "dp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
