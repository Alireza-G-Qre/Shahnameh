{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Data (loading & preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../datasets/shahnameh-labeled.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../datasets/shahnameh-labeled.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.label.unique()\n",
    "num_lb = labels.shape[0]\n",
    "\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import *\n",
    "\n",
    "def pre_processing(dataset):\n",
    "    \n",
    "    normalizer = Normalizer(token_based=True)\n",
    "    stopwords = set(stopwords_list())\n",
    "    \n",
    "    def clean_poems(poem):\n",
    "        tokens = [tk for tk in word_tokenize(poem) if tk not in stopwords and len(tk) > 1]\n",
    "        text = ' '.join(tokens)\n",
    "        return normalizer.normalize(text)\n",
    "    \n",
    "    df['texti'] = df['mesra1'] + ' [SEP] ' + df['mesra2']\n",
    "    df['texti'] = df['texti'].apply(clean_poems)\n",
    "    df['label'] = df['label'].apply(lambda x: label2id[x])\n",
    "    \n",
    "    return df[['texti', 'label']]\n",
    "\n",
    "dfc = pre_processing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    dfc, test_size=0.2,\n",
    "    random_state=42, \n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Baseline (Classical Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Using LogisticRegression\n",
    "pipe = Pipeline([('tfidf', TfidfVectorizer(analyzer='word', max_features=40_000, ngram_range=(1, 3))),\n",
    "                 ('lr', LogisticRegression(multi_class=\"ovr\", solver=\"liblinear\"))])\n",
    "\n",
    "parameters = {'lr__C': [0.1, 0.5, 1, 2, 5, 10, 100, 1000]}\n",
    "\n",
    "classifier = GridSearchCV(pipe, parameters, cv=5, verbose=1).fit(train_df['texti'], train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = classifier.predict(test_df['texti'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "baseline_accuracy = accuracy_score(test_df.label, predicted)\n",
    "\n",
    "print(F\"accuracy_score: {baseline_accuracy},\",\n",
    "      F\"f1_score: {f1_score(test_df.label, predicted, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "mat = confusion_matrix(test_df['label'], predicted)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True, cmap=\"YlGnBu\", vmin=3, vmax=8)\n",
    "\n",
    "print(\n",
    "    '+' * 100 + '\\n' +\n",
    "    '\\n'.join([F'{i} --> {name}' for i, name in enumerate(labels)]) +\n",
    "    '\\n' + '+' * 100\n",
    ")\n",
    "\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Bert (Using Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL = \"HooshvareLab/bert-fa-zwnj-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, num_labels = len(label2id)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "MAX_SEQ_LENGTH=100\n",
    "\n",
    "class BertInputItem:\n",
    "\n",
    "    def __init__(self, text, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.text = text\n",
    "        self.label_id = label_id\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        \n",
    "        \n",
    "def convert_examples_to_inputs(example_texts, example_labels, label2idx, max_seq_length, tokenizer):\n",
    "    \n",
    "    input_items = []\n",
    "    examples = zip(example_texts, example_labels)\n",
    "    \n",
    "    for (ex_index, (text, label)) in enumerate(examples):\n",
    "\n",
    "        input_ids = tokenizer.encode(f\"[CLS] {text} [SEP]\")\n",
    "        if len(input_ids) > max_seq_length:\n",
    "            input_ids = input_ids[:max_seq_length]\n",
    "\n",
    "        segment_ids = [0] * len(input_ids)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        input_items.append(\n",
    "            BertInputItem(text=text,\n",
    "                          label_id=label,\n",
    "                          input_ids=input_ids,\n",
    "                          input_mask=input_mask,\n",
    "                          segment_ids=segment_ids))\n",
    "\n",
    "    return input_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, rest = train_test_split(\n",
    "    dfc, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "test_df, val_df = train_test_split(\n",
    "    rest, test_size=0.5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = convert_examples_to_inputs(\n",
    "    train_df['texti'], train_df['label'], label2id, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "val_features = convert_examples_to_inputs(\n",
    "    val_df['texti'], val_df['label'], label2id, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "test_features = convert_examples_to_inputs(\n",
    "    test_df['texti'], test_df['label'], label2id, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "\n",
    "def get_data_loader(features, max_seq_length, batch_size, shuffle=True): \n",
    "\n",
    "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    \n",
    "    data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    dataloader = DataLoader(data, shuffle=shuffle, batch_size=batch_size)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataloader = get_data_loader(train_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=True)\n",
    "dev_dataloader = get_data_loader(val_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = get_data_loader(test_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    predicted_labels, correct_labels = [], []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(dataloader, desc=\"Evaluation iteration\")):\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids, attention_mask=input_mask,\n",
    "                            token_type_ids=segment_ids, labels=label_ids)\n",
    "            \n",
    "            tmp_eval_loss, logits = output['loss'], output['logits']\n",
    "        \n",
    "        outputs = np.argmax(logits.to('cpu'), axis=1)\n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "        \n",
    "        predicted_labels += list(outputs)\n",
    "        correct_labels += list(label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    \n",
    "    correct_labels = np.array(correct_labels)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "        \n",
    "    return eval_loss, correct_labels, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from torch.optim import AdamW\n",
    "\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "NUM_TRAIN_EPOCHS = 20 #changed!\n",
    "\n",
    "num_train_steps = int(len(train_dataloader.dataset) / BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS * NUM_TRAIN_EPOCHS)\n",
    "start_factor = 0.5\n",
    "learning_rate = 5e-5\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = LinearLR(optimizer, start_factor=start_factor, total_iters=num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "PATIENCE = 2\n",
    "MAX_GRAD_NORM = 5\n",
    "OUTPUT_DIR = \"./results\"\n",
    "MODEL_FILE_NAME = \"shahnameh_model.bin\"\n",
    "\n",
    "loss_history = []\n",
    "no_improvement = 0\n",
    "for _ in trange(NUM_TRAIN_EPOCHS, desc=\"Epoch\"):\n",
    "    model.train()\n",
    "    \n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training iteration\")):\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids, attention_mask=input_mask, \n",
    "            token_type_ids=segment_ids, labels=label_ids)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "\n",
    "        if GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "\n",
    "        loss.backward()\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)  \n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            \n",
    "    val_loss, _, _ = evaluate(model, dev_dataloader)\n",
    "    \n",
    "    print(\"Loss history:\", loss_history)\n",
    "    print(\"Val loss:\", val_loss)\n",
    "    \n",
    "    if len(loss_history) == 0 or val_loss < min(loss_history):\n",
    "        no_improvement = 0\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model\n",
    "        output_model_file = os.path.join(OUTPUT_DIR, MODEL_FILE_NAME)\n",
    "        torch.save(model_to_save.state_dict(), output_model_file)\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "    \n",
    "    if no_improvement >= PATIENCE: \n",
    "        print(\"No improvement on development set. Finish training.\")\n",
    "        break\n",
    "    \n",
    "    loss_history.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = torch.load(\n",
    "    os.path.join(OUTPUT_DIR, MODEL_FILE_NAME), map_location=lambda storage, loc: storage)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    BERT_MODEL, state_dict=model_state_dict, num_labels = len(labels)).to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "_, train_correct, train_predicted = evaluate(model, train_dataloader)\n",
    "_, dev_correct, dev_predicted = evaluate(model, dev_dataloader)\n",
    "_, test_correct, test_predicted = evaluate(model, test_dataloader)\n",
    "\n",
    "print(\"Training performance:\", \n",
    "      precision_recall_fscore_support(train_correct, train_predicted, average=\"macro\"))\n",
    "print(\"Test performance:\", \n",
    "      precision_recall_fscore_support(test_correct, test_predicted, average=\"macro\"))\n",
    "print(\"Development performance:\", \n",
    "      precision_recall_fscore_support(dev_correct, dev_predicted, average=\"macro\"))\n",
    "\n",
    "bert_accuracy = np.mean(test_predicted == test_correct)\n",
    "\n",
    "print(classification_report(test_correct, test_predicted, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame({\"accuracy\": {\"baseline\": baseline_accuracy, \"BERT\": bert_accuracy}})\n",
    "plt.rcParams['figure.figsize'] = (7,4)\n",
    "df.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Huggingface (Text Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    dfc, test_size=0.2,\n",
    "    random_state=42, \n",
    "    shuffle=True)\n",
    "\n",
    "train_dataset, test_dataset = Dataset.from_dict(train_df), Dataset.from_dict(test_df)\n",
    "\n",
    "dataset = DatasetDict({\"train\":train_dataset,\"test\":test_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL = \"HooshvareLab/bert-fa-zwnj-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"texti\"], truncation=True)\n",
    "\n",
    "tokenized_imdb = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BERT_MODEL, num_labels=len(label2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10, #changed!\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_imdb[\"train\"],\n",
    "    eval_dataset=tokenized_imdb[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"رستم به دیدن اسفندیار رفت ولی نبود و مجبور شد بدون بزم برگردد زرشک\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_classes_are(texts):\n",
    "\n",
    "    labels = [int(x['label'].split('_')[1]) for x in classifier(texts)]\n",
    "    return labels, [id2label[x] for x in labels]\n",
    "\n",
    "which_classes_are([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = which_classes_are(dataset['test']['texti'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"f1\")\n",
    "\n",
    "print(\"f1_score: \", metric.compute(\n",
    "    predictions=predictions[0], references=dataset['test']['label'], average='macro'))\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "print(\"accuracy: \", metric.compute(\n",
    "    predictions=predictions[0], references=dataset['test']['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "mat = confusion_matrix(dataset['test']['label'], predictions[0])\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True, cmap=\"YlGnBu\", vmin=3, vmax=8)\n",
    "\n",
    "print(\n",
    "    '+' * 100 + '\\n' +\n",
    "    '\\n'.join([F'{i} --> {name}' for i, name in enumerate(labels)]) +\n",
    "    '\\n' + '+' * 100\n",
    ")\n",
    "\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "dp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
