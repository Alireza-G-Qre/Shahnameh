{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f891337e",
   "metadata": {},
   "source": [
    "# Data loading and normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93263ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy hazm scikit-learn gensim transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63c193cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "poems = list(line[1:-1] for line in\n",
    "             io.open('../datasets/shahnameh.txt', mode=\"r\", encoding=\"utf-8\").readlines())\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hazm\n",
    "\n",
    "# TODO: better stopwords to improve\n",
    "costums = [\n",
    "    'زین',\n",
    "    'مگر',\n",
    "    'گر',\n",
    "    'کز',\n",
    "    'پس',\n",
    "]\n",
    "stopwords = set(hazm.stopwords_list() + costums)\n",
    "\n",
    "poems = np.array(poems)\n",
    "poems = np.apply_along_axis(' / '.join, 1, poems.reshape(-1, 2))\n",
    "\n",
    "df = pd.DataFrame(poems, columns=['poems'])\n",
    "\n",
    "normalizer = hazm.Normalizer(token_based=True)\n",
    "\n",
    "# find better persian poems normalization and cleaning\n",
    "def clean_poems(poem):\n",
    "    tokens = [tk for tk in hazm.word_tokenize(poem) if tk not in stopwords and len(tk) > 1]\n",
    "    text = ' '.join(tokens)\n",
    "    return normalizer.normalize(text)\n",
    "\n",
    "df['changed'] = df.poems.apply(clean_poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "588178a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poems</th>\n",
       "      <th>changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8493</th>\n",
       "      <td>یا تا همه دست نیکی بریم / هان جهان را به بد نسپر</td>\n",
       "      <td>دست نیکی بریم هان جهان بد نسپر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46032</th>\n",
       "      <td>رآنکس که او از در کار بود / دان مرز با او سزاوار</td>\n",
       "      <td>رآنکس کار دان مرز سزاوار</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48006</th>\n",
       "      <td>ه جاوید باد آن خردمند مرد / میشه به کام دلش کارک</td>\n",
       "      <td>جاوید باد خردمند مرد میشه کام دلش کارک</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27878</th>\n",
       "      <td>ی کین نهان گردد از روی بوم / ود گرز پولاد برسان</td>\n",
       "      <td>کین نهان بوم ود گرز پولاد برسان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41393</th>\n",
       "      <td>دیگر که چندان دلیر و سوار / ه بود اندر ایران همه</td>\n",
       "      <td>چندان دلیر سوار ه_بود اندر ایران</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25083</th>\n",
       "      <td>یاده همان شاه دستش بدست / یا و در او را بجای نشس</td>\n",
       "      <td>یاده شاه دستش بدست بجای نشس</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41944</th>\n",
       "      <td>رفتند گویندگان نزد شاه / نیده به گفتند زان بی گن</td>\n",
       "      <td>رفتند گویندگان نزد شاه نیده گفتند زان گن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39253</th>\n",
       "      <td>پاکی و از پارسایی زن / ه هم غمگسارست و هم رای ز</td>\n",
       "      <td>پاکی پارسایی زن غمگسارست رای</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23457</th>\n",
       "      <td>و بگذشت یک چند گریان چنین / بخشود بر وی جهان آفر</td>\n",
       "      <td>بگذشت گریان بخشود جهان آفر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5259</th>\n",
       "      <td>ر ای دون که تنگ اندر آید سخن / ه جنگ اندرون هیچ</td>\n",
       "      <td>ای دون تنگ اندر آید سخن جنگ اندرون</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  poems  \\\n",
       "8493   یا تا همه دست نیکی بریم / هان جهان را به بد نسپر   \n",
       "46032  رآنکس که او از در کار بود / دان مرز با او سزاوار   \n",
       "48006  ه جاوید باد آن خردمند مرد / میشه به کام دلش کارک   \n",
       "27878  ی کین نهان گردد از روی بوم / ود گرز پولاد برسان    \n",
       "41393  دیگر که چندان دلیر و سوار / ه بود اندر ایران همه   \n",
       "25083  یاده همان شاه دستش بدست / یا و در او را بجای نشس   \n",
       "41944  رفتند گویندگان نزد شاه / نیده به گفتند زان بی گن   \n",
       "39253   پاکی و از پارسایی زن / ه هم غمگسارست و هم رای ز   \n",
       "23457  و بگذشت یک چند گریان چنین / بخشود بر وی جهان آفر   \n",
       "5259   ر ای دون که تنگ اندر آید سخن / ه جنگ اندرون هیچ    \n",
       "\n",
       "                                        changed  \n",
       "8493             دست نیکی بریم هان جهان بد نسپر  \n",
       "46032                  رآنکس کار دان مرز سزاوار  \n",
       "48006    جاوید باد خردمند مرد میشه کام دلش کارک  \n",
       "27878           کین نهان بوم ود گرز پولاد برسان  \n",
       "41393          چندان دلیر سوار ه_بود اندر ایران  \n",
       "25083               یاده شاه دستش بدست بجای نشس  \n",
       "41944  رفتند گویندگان نزد شاه نیده گفتند زان گن  \n",
       "39253              پاکی پارسایی زن غمگسارست رای  \n",
       "23457                بگذشت گریان بخشود جهان آفر  \n",
       "5259         ای دون تنگ اندر آید سخن جنگ اندرون  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98799951",
   "metadata": {},
   "source": [
    "# Tfidf and Boolean approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de31fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# TODO: check bigram with ngram_range=(1, 2) and increase max_features\n",
    "pipe = Pipeline([('count', CountVectorizer(analyzer='word', ngram_range=(1, 1), max_features=15_000)),\n",
    "                 ('tfidf', TfidfTransformer(sublinear_tf=True))]).fit(df.changed)\n",
    "\n",
    "def get_document_vectors(series):\n",
    "    series = [clean_poems(doc) for doc in series]\n",
    "    boolw_vec = pipe['count'].transform(series).toarray().astype(bool).astype(int)\n",
    "    norm = np.linalg.norm(boolw_vec, axis=1).reshape(-1, 1)\n",
    "    return pipe.transform(series).toarray() , boolw_vec / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81461de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_documents, boolw_documents = get_document_vectors(df.poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81cd0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-10\n",
    "\n",
    "def get_similars_by_cosine_distance(vector, documents, n=5):\n",
    "    sq_vector = np.squeeze(vector)\n",
    "    similarity = documents.dot(sq_vector) / (np.linalg.norm(documents, axis=1) * np.linalg.norm(sq_vector) + eps)\n",
    "    sorted_indx = np.argsort(similarity)\n",
    "    \n",
    "    return list(zip(df.poems[sorted_indx[-n:]], similarity[sorted_indx[-n:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408dfa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector, boolw_vector = \\\n",
    "    get_document_vectors(['که تاج سر شهریاران توی که گوید که پور شبانان توی'])\n",
    "\n",
    "# TODO: better format to report similarity\n",
    "print('-' * 100)\n",
    "for poem, sym in get_similars_by_cosine_distance(tfidf_vector, tfidf_documents):\n",
    "    print(\"tfidf: \\\"{}\\\" \\t with similarity of {:.2f}\".format(poem, sym))\n",
    "\n",
    "print('-' * 100)\n",
    "for poem, sym in get_similars_by_cosine_distance(boolw_vector, boolw_documents):\n",
    "    print(\"boolw: \\\"{}\\\" \\t with similarity of {:.2f}\".format(poem, sym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_idfs = dict(zip(pipe['count'].get_feature_names_out(), pipe['tfidf'].idf_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a6fbf",
   "metadata": {},
   "source": [
    "# Combining word embedding and idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce9d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from hazm import word_tokenize\n",
    "\n",
    "word2vec = KeyedVectors.load_word2vec_format('../models/farsi_literature_word2vec_model.txt')\n",
    "\n",
    "# TODO: check appropriate stopwords\n",
    "def embed(poem):\n",
    "    \n",
    "    poem = clean_poems(poem)\n",
    "    def get_wrod2vector(word):\n",
    "        return word2vec[word] if word in word2vec else np.zeros(100)\n",
    "    \n",
    "    embedding_vectors = [get_wrod2vector(wo) * word_idfs.get(wo, 0) for wo in word_tokenize(poem)]\n",
    "    return np.sum(embedding_vectors, axis=0).tolist()\n",
    "\n",
    "poems_embeddings = np.array(df.changed.apply(embed).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47ad011",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_embedding = np.array(embed('به نام خداوند جان و خرد کزین برتر اندیشه برنگذرد'))\n",
    "\n",
    "# TODO: better format to report similarity\n",
    "print('-' * 100)\n",
    "for poem, sym in get_similars_by_cosine_distance(sample_embedding, poems_embeddings):\n",
    "    print(\"embedding: \\\"{}\\\" \\t with similarity of {:.2f}\".format(poem, sym))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a38068",
   "metadata": {},
   "source": [
    "# Use BigBird and ParsBert last hidden state as embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tran import TransformerEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a1128",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = TransformerEmbedding()\n",
    "\n",
    "# Only for the first time\n",
    "embedder.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3af9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/embeddings-bigbird.npy', 'rb') as file:\n",
    "    poems_embeddings = np.load(file)\n",
    "sample_embedding = tran.get_transformer_embedding(['به نام خداوند جان و خرد کزین برتر اندیشه برنگذرد'], 'bigbird')\n",
    "\n",
    "# TODO: better format to report similarity\n",
    "print('-' * 100)\n",
    "for poem, sym in get_similars_by_cosine_distance(sample_embedding, poems_embeddings):\n",
    "    print(\"embedding: \\\"{}\\\" \\t with similarity of {:.2f}\".format(poem, sym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f2766",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/embeddings-parsbert.npy', 'rb') as file:\n",
    "    poems_embeddings = np.load(file)\n",
    "sample_embedding = get_transformer_embedding(['چو ضحاک بشنید اندیشه کرد ز خون پدر شد دلش پر ز د'])\n",
    "\n",
    "# TODO: better format to report similarity\n",
    "print('-' * 100)\n",
    "for poem, sym in get_similars_by_cosine_distance(sample_embedding, poems_embeddings):\n",
    "    print(\"embedding: \\\"{}\\\" \\t with similarity of {:.2f}\".format(poem, sym))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
